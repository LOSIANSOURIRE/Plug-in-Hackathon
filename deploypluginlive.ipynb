{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f18398e219054f6b806918084af979b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1157f08a2c8d444caf6d90f02cc28e30",
              "IPY_MODEL_6309c50a276f481bb6e6fd243cb30ef8",
              "IPY_MODEL_65bd7f3f323540dfb7099d7171587f5c"
            ],
            "layout": "IPY_MODEL_881ce7e6c9e4434292ee587d756d039b"
          }
        },
        "1157f08a2c8d444caf6d90f02cc28e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be1a6172607b4445be5a63673edeba75",
            "placeholder": "​",
            "style": "IPY_MODEL_2f72c06518a64c429d255d5963fb7beb",
            "value": "model.safetensors: 100%"
          }
        },
        "6309c50a276f481bb6e6fd243cb30ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22993467b2d1472e8fb19aed1e1a24e6",
            "max": 1261926380,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1721f75f5c44146bafb4c765bbc0cfb",
            "value": 1261926380
          }
        },
        "65bd7f3f323540dfb7099d7171587f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9134efa8ea9544f091e052123237632c",
            "placeholder": "​",
            "style": "IPY_MODEL_bdeddf280f374647b455ed3bb87085bc",
            "value": " 1.26G/1.26G [00:02&lt;00:00, 42.8MB/s]"
          }
        },
        "881ce7e6c9e4434292ee587d756d039b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be1a6172607b4445be5a63673edeba75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f72c06518a64c429d255d5963fb7beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22993467b2d1472e8fb19aed1e1a24e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1721f75f5c44146bafb4c765bbc0cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9134efa8ea9544f091e052123237632c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdeddf280f374647b455ed3bb87085bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub language-tool-python librosa transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irahXTdtdvQg",
        "outputId": "17c190c2-7926-4a39-8cfd-ee0fccbefd6e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting language-tool-python\n",
            "  Downloading language_tool_python-2.8.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from language-tool-python) (24.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from language-tool-python) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from language-tool-python) (4.66.6)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from language-tool-python) (0.45.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->language-tool-python) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->language-tool-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->language-tool-python) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->language-tool-python) (2024.8.30)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading language_tool_python-2.8.1-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: pydub, language-tool-python\n",
            "Successfully installed language-tool-python-2.8.1 pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube ffmpeg openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxexl0lal_gC",
        "outputId": "82e1da7c-4215-4475-b1b6-e97954764e14"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=27c62f863ea10ae69cdd57f378c0ba85270d1b9d358d94a537dec13d464c9840\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg, pytube\n",
            "Successfully installed ffmpeg-1.4 pytube-15.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-speech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "dwM4XPjmNobn",
        "outputId": "05f6ba9c-f87e-44b5-ca11-c2ee90c5d9c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-cloud-speech\n",
            "  Downloading google_cloud_speech-2.28.1-py2.py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2.19.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (4.25.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (1.68.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2024.8.30)\n",
            "Downloading google_cloud_speech-2.28.1-py2.py3-none-any.whl (304 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/305.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.0/305.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-cloud-speech\n",
            "Successfully installed google-cloud-speech-2.28.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "d27c7da7393e4b368f022367997f0d45"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "from google.cloud import speech"
      ],
      "metadata": {
        "id": "DVMBiBCEWali"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS']=\"\""
      ],
      "metadata": {
        "id": "xxnplawUX3iD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $GOOGLE_APPLICATION_CREDENTIALS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J4g6-AXYFYd",
        "outputId": "85d60590-5696-4dbb-c2d5-1c3aa932ed7f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pluginlive-444306-d4f6569e136a.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install eng-to-ipa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2dRsI-Og0HJ",
        "outputId": "3423e843-c08e-4aa7-fb75-a7b0535bb398"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting eng-to-ipa\n",
            "  Downloading eng_to_ipa-0.0.2.tar.gz (2.8 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/2.8 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: eng-to-ipa\n",
            "  Building wheel for eng-to-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eng-to-ipa: filename=eng_to_ipa-0.0.2-py3-none-any.whl size=2822601 sha256=a18521cd0397f5aa045224978f6bd7b0fca850b612771e4b3d4b22ac418bf1cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/ab/07/fe6722f710d8ef8bd0ccb4eb689ef96f5552f3fc0c80c1aa9c\n",
            "Successfully built eng-to-ipa\n",
            "Installing collected packages: eng-to-ipa\n",
            "Successfully installed eng-to-ipa-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=\"\")\n",
        "language_model = genai.GenerativeModel(\"gemini-pro\")"
      ],
      "metadata": {
        "id": "wthOz37Cl3KA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from pydub import AudioSegment, silence\n",
        "import language_tool_python as lt\n",
        "import librosa\n",
        "import numpy as np\n",
        "from openai import OpenAI\n",
        "import string\n",
        "import eng_to_ipa as ipa\n",
        "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
        "import torchaudio\n",
        "\n",
        "input_audio_path = \"/content/sample.wav\"\n",
        "temp_audio_path = \"resampled.wav\"\n",
        "\n",
        "import soundfile as sf\n",
        "\n",
        "def preprocess_audio(file_path, target_sr=16000):\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "    if sr != target_sr:\n",
        "        y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
        "    sf.write(temp_audio_path, y, target_sr, subtype=\"PCM_16\")\n",
        "    return temp_audio_path, target_sr\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "\n",
        "    client = speech.SpeechClient()\n",
        "\n",
        "\n",
        "    with open(audio_path, \"rb\") as audio_file:\n",
        "        content = audio_file.read()\n",
        "\n",
        "    audio = speech.RecognitionAudio(content=content)\n",
        "\n",
        "\n",
        "    config = speech.RecognitionConfig(\n",
        "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
        "        language_code=\"en-US\",\n",
        "        enable_automatic_punctuation=True,\n",
        "    )\n",
        "\n",
        "\n",
        "    response = client.recognize(config=config, audio=audio)\n",
        "\n",
        "\n",
        "    transcription = \" \".join([result.alternatives[0].transcript for result in response.results])\n",
        "    return transcription\n",
        "def grammar_analysis(text):\n",
        "    prompt = f\"\"\"\n",
        "    You are an English grammar expert. You will be provided with the response of a candidate.\n",
        "    Your task is to parse the response and generate the number of grammatical errors, evaluating the\n",
        "    candidate's grammatical correctness. Avoid considering punctuation marks because this is transcribed.\n",
        "    Candidate's Response:\n",
        "    {text}\n",
        "    Please provide the number of grammatical errors without any explanation.\n",
        "    \"\"\"\n",
        "\n",
        "    response = language_model.generate_content(prompt)\n",
        "    grammar_errors = response.text\n",
        "    return int(grammar_errors)\n",
        "def text_to_phonemes(text):\n",
        "    phonemes = ipa.convert(text)\n",
        "    return phonemes.split()\n",
        "def pronunciation_analysis(transcribed_text, original_audio_path):\n",
        "    word_count = len(transcribed_text.split())\n",
        "    audio_duration = librosa.get_duration(filename=original_audio_path)\n",
        "    speaking_rate = word_count / audio_duration\n",
        "    return word_count, audio_duration, speaking_rate\n",
        "\n",
        "def fluency_analysis(transcribed_text, audio_path):\n",
        "    audio = AudioSegment.from_file(audio_path)\n",
        "    silences = silence.detect_silence(audio, min_silence_len=2000, silence_thresh=-40)\n",
        "    print(silences)\n",
        "    num_pauses = len(silences)\n",
        "    filler_words = [\"um\", \"uh\", \"like\", \"so\", \"actually\", \"basically\", \"literally\", \"you know\"]\n",
        "    words = transcribed_text.translate(str.maketrans('', '', string.punctuation)).split()\n",
        "    detected_fillers = []\n",
        "    for i in range(len(words)):\n",
        "        if words[i].lower() in filler_words:\n",
        "            detected_fillers.append(words[i])\n",
        "        if i < len(words) - 1 and f\"{words[i].lower()} {words[i+1].lower()}\" == \"you know\":\n",
        "            detected_fillers.append(\"you know\")\n",
        "    return num_pauses, detected_fillers\n",
        "\n",
        "def phonetic_analysis(transcribed_text, audio_path):\n",
        "    expected_phonemes = text_to_phonemes(transcribed_text)\n",
        "    processor = Wav2Vec2Processor.from_pretrained(\"Bluecast/wav2vec2-Phoneme\")\n",
        "    model = Wav2Vec2ForCTC.from_pretrained(\"Bluecast/wav2vec2-Phoneme\")\n",
        "    audio, rate = torchaudio.load(\"/content/sample.wav\", normalize=True, channels_first=True)\n",
        "    if audio.shape[0] == 2:\n",
        "        audio = audio.mean(dim=0, keepdim=True)\n",
        "    target_rate = 16000\n",
        "    if rate != target_rate:\n",
        "        transform = torchaudio.transforms.Resample(orig_freq=rate, new_freq=target_rate)\n",
        "        audio = transform(audio)\n",
        "        rate = target_rate\n",
        "    audio = audio.squeeze(0)\n",
        "    inputs = processor(audio, sampling_rate=rate, return_tensors=\"pt\", padding=True)\n",
        "    logits = model(inputs.input_values).logits\n",
        "    pred_ids = logits.argmax(axis=-1)\n",
        "    phonemes = processor.batch_decode(pred_ids)\n",
        "    if isinstance(phonemes, list):\n",
        "        phonemes = phonemes[0].split()\n",
        "    phoneme_to_ipa = {\n",
        "    'aa': 'ɑ',   # Father\n",
        "    'ae': 'æ',   # Cat\n",
        "    'ah': 'ʌ',   # Cup\n",
        "    'ao': 'ɔ',   # Thought\n",
        "    'aw': 'aʊ',  # House\n",
        "    'ax': 'ə',   # About\n",
        "    'ax-h': 'ə', # Ahead (unstressed)\n",
        "    'axr': 'ɚ',  # Butter (unstressed)\n",
        "    'ay': 'aɪ',  # My\n",
        "    'eh': 'ɛ',   # Bed\n",
        "    'el': 'l̩',  # Syllabic 'l' (Bottle)\n",
        "    'em': 'm̩',  # Syllabic 'm' (Hymn)\n",
        "    'en': 'n̩',  # Syllabic 'n' (Button)\n",
        "    'er': 'ɝ',   # Bird (stressed)\n",
        "    'ey': 'eɪ',  # They\n",
        "    'ih': 'ɪ',   # Sit\n",
        "    'iy': 'i',   # See\n",
        "    'ow': 'oʊ',  # Go\n",
        "    'oy': 'ɔɪ',  # Boy\n",
        "    'uh': 'ʊ',   # Put\n",
        "    'uw': 'u',   # Blue\n",
        "    'ux': 'ʉ',   # Goose (Northern American English)\n",
        "    'b': 'b',    # Bat\n",
        "    'ch': 'tʃ',  # Cheese\n",
        "    'd': 'd',    # Dog\n",
        "    'dh': 'ð',   # This\n",
        "    'dx': 'ɾ',   # Flap 't' (Butter)\n",
        "    'eh': 'ɛ',   # Bed\n",
        "    'f': 'f',    # Fish\n",
        "    'g': 'g',    # Go\n",
        "    'hh': 'h',   # Hat\n",
        "    'jh': 'dʒ',  # Jump\n",
        "    'k': 'k',    # Cat\n",
        "    'l': 'l',    # Leg\n",
        "    'm': 'm',    # Man\n",
        "    'n': 'n',    # Net\n",
        "    'ng': 'ŋ',   # Sing\n",
        "    'p': 'p',    # Pet\n",
        "    'q': 'ʔ',    # Glottal Stop (Uh-oh)\n",
        "    'r': 'ɹ',    # Red\n",
        "    's': 's',    # Sun\n",
        "    'sh': 'ʃ',   # Shoe\n",
        "    't': 't',    # Top\n",
        "    'th': 'θ',   # Thing\n",
        "    'v': 'v',    # Van\n",
        "    'w': 'w',    # Wet\n",
        "    'y': 'j',    # Yes\n",
        "    'z': 'z',    # Zoo\n",
        "    'zh': 'ʒ',   # Measure\n",
        "    }\n",
        "    ipa_transcription = [phoneme_to_ipa.get(phoneme, phoneme) for phoneme in phonemes]\n",
        "    return ' '.join(ipa_transcription), expected_phonemes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Preprocessing audio...\")\n",
        "processed_path, sr = preprocess_audio(input_audio_path)\n",
        "\n",
        "print(\"Transcribing audio...\")\n",
        "transcription = transcribe_audio(processed_path)\n",
        "print(f\"Transcription: {transcription}\")\n",
        "\n",
        "print(\"Evaluating grammar...\")\n",
        "grammar_errors = grammar_analysis(transcription)\n",
        "print(f\"Grammar Errors: {grammar_errors}\")\n",
        "\n",
        "print(\"Evaluating pronunciation...\")\n",
        "speaker_phonemes, expected_phonemes= phonetic_analysis(transcription, processed_path)\n",
        "print(f\"Phonemes: {expected_phonemes}\")\n",
        "\n",
        "print(\"Evaluating fluency...\")\n",
        "num_pauses, filler_words = fluency_analysis(transcription, processed_path)\n",
        "word_count, duration, speaking_rate = pronunciation_analysis(transcription, processed_path)\n",
        "print(f\"Word Count: {word_count}\")\n",
        "print(f\"Audio Duration: {duration:.2f} seconds\")\n",
        "print(f\"Speaking Rate: {speaking_rate:.2f} words per second\")\n",
        "print(f\"Number of Pauses: {num_pauses}\")\n",
        "print(f\"Filler Words Detected: {len(filler_words)}\")\n",
        "\n",
        "print(\"\\n### Final Assessment ###\")\n",
        "print(f\"Transcription: {transcription}\")\n",
        "print(f\"Grammar Errors:{grammar_errors}\")\n",
        "print(f\"Word Count: {word_count}, Speaking Rate: {speaking_rate:.2f} WPS\")\n",
        "print(f\"Number of Pauses: {num_pauses}\")\n",
        "print(f\"Phonemes: {expected_phonemes}\")\n",
        "print(f\"Filler Words Detected: {filler_words}\")\n",
        "\n",
        "\n",
        "if os.path.exists(temp_audio_path):\n",
        "    os.remove(temp_audio_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483,
          "referenced_widgets": [
            "f18398e219054f6b806918084af979b6",
            "1157f08a2c8d444caf6d90f02cc28e30",
            "6309c50a276f481bb6e6fd243cb30ef8",
            "65bd7f3f323540dfb7099d7171587f5c",
            "881ce7e6c9e4434292ee587d756d039b",
            "be1a6172607b4445be5a63673edeba75",
            "2f72c06518a64c429d255d5963fb7beb",
            "22993467b2d1472e8fb19aed1e1a24e6",
            "f1721f75f5c44146bafb4c765bbc0cfb",
            "9134efa8ea9544f091e052123237632c",
            "bdeddf280f374647b455ed3bb87085bc"
          ]
        },
        "id": "XtyOEHCrTW1I",
        "outputId": "f42dbea5-2a68-4120-ca04-edeb4821ba4d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing audio...\n",
            "Transcribing audio...\n",
            "Transcription: Hey guys, how are you doing?\n",
            "Evaluating grammar...\n",
            "Grammar Errors: 1\n",
            "Evaluating pronunciation...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:  92%|#########2| 1.16G/1.26G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f18398e219054f6b806918084af979b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phonemes: ['heɪ', 'gaɪz,', 'haʊ', 'ər', 'ju', 'duɪŋ?']\n",
            "Evaluating fluency...\n",
            "[]\n",
            "Word Count: 6\n",
            "Audio Duration: 4.71 seconds\n",
            "Speaking Rate: 1.27 words per second\n",
            "Number of Pauses: 0\n",
            "Filler Words Detected: 0\n",
            "\n",
            "### Final Assessment ###\n",
            "Transcription: Hey guys, how are you doing?\n",
            "Grammar Errors:1\n",
            "Word Count: 6, Speaking Rate: 1.27 WPS\n",
            "Number of Pauses: 0\n",
            "Phonemes: ['heɪ', 'gaɪz,', 'haʊ', 'ər', 'ju', 'duɪŋ?']\n",
            "Filler Words Detected: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-ac9ed9556c26>:66: FutureWarning: get_duration() keyword argument 'filename' has been renamed to 'path' in version 0.10.0.\n",
            "\tThis alias will be removed in version 1.0.\n",
            "  audio_duration = librosa.get_duration(filename=original_audio_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phonemes_speaker = speaker_phonemes.replace(\" \", \"\")\n",
        "print(phonemes_speaker)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWmaqt0JrBXN",
        "outputId": "ddc66a58-3a2f-4d2b-b852-ccfd5d84cc4a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ʌgaɪðhaʊɑɹjuduɪŋ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phonemes_without_punctuation = [''.join(ch for ch in phoneme if ch not in string.punctuation) for phoneme in expected_phonemes]\n",
        "phonemes_true = ''.join(phonemes_without_punctuation)\n",
        "print(phonemes_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSPZiqVeqf_2",
        "outputId": "188266ae-c15e-46ed-e5b6-5fc806a4c466"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heɪgaɪzhaʊərjuduɪŋ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import Levenshtein\n",
        "\n",
        "def scoring_metrics(transcription, grammar_errors, num_pauses, filler_words, true_phonemes, speaker_phonemes):\n",
        "  words= transcription.split(' ')\n",
        "  num_words=len(words)\n",
        "  grammar_mistake = 1- (grammar_errors/num_words)\n",
        "  grammar_score= 5*grammar_mistake\n",
        "  grammar_score=round(grammar_score,2)\n",
        "  fluency_mistake = 1- ((num_pauses+len(filler_words))/num_words)\n",
        "  fluency_score=5*fluency_mistake\n",
        "  fluency_score=round(fluency_score, 2)\n",
        "  len_s1, len_s2 = len(true_phonemes), len(speaker_phonemes)\n",
        "  dp = [[0] * (len_s2 + 1) for _ in range(len_s1 + 1)]\n",
        "  for i in range(len_s1 + 1):\n",
        "      dp[i][0] = i\n",
        "  for j in range(len_s2 + 1):\n",
        "      dp[0][j] = j\n",
        "  for i in range(1, len_s1 + 1):\n",
        "      for j in range(1, len_s2 + 1):\n",
        "          cost = 0 if true_phonemes[i - 1] == speaker_phonemes[j - 1] else 1\n",
        "          dp[i][j] = min(dp[i - 1][j] + 1, dp[i][j - 1] + 1, dp[i - 1][j - 1] + cost)\n",
        "  edit_distance = dp[len_s1][len_s2]\n",
        "  max_length = max(len(expected_phonemes), len(speaker_phonemes))\n",
        "  pronunciation_score = ((max_length - edit_distance) / max_length) * 5\n",
        "  pronunciation_score=round(pronunciation_score, 2)\n",
        "  return grammar_score, fluency_score, pronunciation_score+0.5\n",
        "\n",
        "grammar_score, fluency_score, pronunciation_score=scoring_metrics(transcription, grammar_errors, num_pauses, filler_words, \"phonims\", \"phonemes\")\n",
        "print(f\"Grammar Score: {grammar_score}\")\n",
        "print(f\"Fluency Score: {fluency_score}\")\n",
        "print(f\"Pronunciation Score: {pronunciation_score}\")\n",
        "\n",
        "def generate_positive_feedback(grammar_score, fluency_score):\n",
        "    feedback = {}\n",
        "\n",
        "    # Grammar feedback\n",
        "    if grammar_score >= 4.90:\n",
        "        feedback['grammar'] = \"Your grammar is outstanding, with exceptional clarity and no noticeable errors. Keep up the excellent work!\"\n",
        "    elif grammar_score >= 4.75:\n",
        "        feedback['grammar'] = \"Your grammar is excellent, with very few, nearly unnoticeable errors. A little more attention to detail will make it flawless.\"\n",
        "    elif grammar_score >= 4.60:\n",
        "        feedback['grammar'] = \"Your grammar is strong, with only occasional minor errors. With consistent refinement, you can reach perfection.\"\n",
        "    elif grammar_score >= 4.45:\n",
        "        feedback['grammar'] = \"Your grammar is very good, with a few minor areas for improvement. Regular practice will help you polish these aspects.\"\n",
        "    elif grammar_score >= 4.30:\n",
        "        feedback['grammar'] = \"Your grammar is good and clear, though some noticeable errors exist. Focused practice can enhance your clarity even further.\"\n",
        "    elif grammar_score >= 4.00:\n",
        "        feedback['grammar'] = \"Your grammar is adequate and generally understandable, but there is room for improvement in clarity and precision. Keep refining your skills.\"\n",
        "    elif grammar_score >= 3.75:\n",
        "        feedback['grammar'] = \"Your grammar is improving, though noticeable errors are present. Continued practice and attention to detail will help you progress.\"\n",
        "    elif grammar_score >= 3.50:\n",
        "        feedback['grammar'] = \"Your grammar shows potential, but frequent errors can distract from clarity. Focused effort on common patterns can significantly enhance your accuracy.\"\n",
        "    else:\n",
        "        feedback['grammar'] = \"Your grammar is developing, but it requires consistent attention. Identify frequent errors and work on them to strengthen your communication skills.\"\n",
        "\n",
        "    # Fluency feedback\n",
        "    if fluency_score >= 4.90:\n",
        "        feedback['fluency'] = \"Your fluency is remarkable, with an effortless and natural flow. It is a pleasure to listen to!\"\n",
        "    elif fluency_score >= 4.75:\n",
        "        feedback['fluency'] = \"Your fluency is very strong, with rare and minor hesitations. Continued practice will make it even more seamless.\"\n",
        "    elif fluency_score >= 4.60:\n",
        "        feedback['fluency'] = \"Your fluency is strong, with only slight hesitations. Practicing in real-time settings will make your speech even more fluid.\"\n",
        "    elif fluency_score >= 4.45:\n",
        "        feedback['fluency'] = \"Your fluency is good, with occasional hesitations. Regular speaking exercises will help you improve your confidence and flow.\"\n",
        "    elif fluency_score >= 4.30:\n",
        "        feedback['fluency'] = \"Your fluency is moderate, with room for improvement. Engaging in more speaking opportunities will help make your speech more natural.\"\n",
        "    elif fluency_score >= 4.00:\n",
        "        feedback['fluency'] = \"Your fluency is adequate but could be smoother. Focused exercises in spontaneous speaking will enhance your confidence.\"\n",
        "    elif fluency_score >= 3.75:\n",
        "        feedback['fluency'] = \"Your fluency is progressing, though noticeable pauses may affect the flow. Practicing continuous speech will help reduce hesitations.\"\n",
        "    elif fluency_score >= 3.50:\n",
        "        feedback['fluency'] = \"Your fluency shows promise, but frequent hesitations disrupt the flow. Regular practice and confidence-building activities can help improve this.\"\n",
        "    else:\n",
        "        feedback['fluency'] = \"Your fluency is developing, but consistent practice will greatly enhance your flow. Don’t hesitate to express yourself confidently!\"\n",
        "\n",
        "    # Pronunciation feedback\n",
        "    if pronunciation_score >= 4.90:\n",
        "        feedback['pronunciation'] = \"Your pronunciation is exemplary, with clear and accurate articulation of every word. It’s a pleasure to hear!\"\n",
        "    elif pronunciation_score >= 4.75:\n",
        "        feedback['pronunciation'] = \"Your pronunciation is very strong, with only minor mispronunciations. A little more attention to detail will make it perfect.\"\n",
        "    elif pronunciation_score >= 4.60:\n",
        "        feedback['pronunciation'] = \"Your pronunciation is strong, with occasional mispronunciations. Regular practice will help improve consistency.\"\n",
        "    elif pronunciation_score >= 4.45:\n",
        "        feedback['pronunciation'] = \"Your pronunciation is good, but some sounds may be unclear. Focus on practicing difficult sounds to improve clarity.\"\n",
        "    elif pronunciation_score >= 4.30:\n",
        "        feedback['pronunciation'] = \"Your pronunciation is moderate, with noticeable mispronunciations. Continued practice will improve your accuracy.\"\n",
        "    elif pronunciation_score >= 4.00:\n",
        "        feedback['pronunciation'] = \"Your pronunciation is adequate but could use some improvement. Working on specific sounds will enhance your speech.\"\n",
        "    elif pronunciation_score >= 3.75:\n",
        "        feedback['pronunciation'] = \"Your pronunciation is progressing, but some words are difficult to understand. Regular practice with pronunciation guides can help.\"\n",
        "    elif pronunciation_score >= 3.50:\n",
        "        feedback['pronunciation'] = \"Your pronunciation shows potential, but frequent mispronunciations can hinder understanding. Focused practice will make a big difference.\"\n",
        "    else:\n",
        "        feedback['pronunciation'] = \"Your pronunciation is still developing, but with consistent effort and guidance, you’ll see significant improvements.\"\n",
        "\n",
        "    return feedback\n",
        "\n",
        "\n",
        "feedback = generate_positive_feedback(grammar_score, fluency_score)\n",
        "\n",
        "print(\"Feedback:\")\n",
        "print(\"Grammar:\", feedback['grammar'])\n",
        "print(\"Fluency:\", feedback['fluency'])\n",
        "print(\"Pronunciation:\", feedback['pronunciation'])"
      ],
      "metadata": {
        "id": "wX0IzfzBTFWv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cdf9697-b85f-431f-c6c6-2e40b625f19f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grammar Score: 4.17\n",
            "Fluency Score: 5.0\n",
            "Pronunciation Score: 4.25\n",
            "Feedback:\n",
            "Grammar: Your grammar is adequate and generally understandable, but there is room for improvement in clarity and precision. Keep refining your skills.\n",
            "Fluency: Your fluency is remarkable, with an effortless and natural flow. It is a pleasure to listen to!\n",
            "Pronunciation: Your pronunciation is adequate but could use some improvement. Working on specific sounds will enhance your speech.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_info = {\n",
        "    \"grammar_score\": {grammar_score},\n",
        "    \"fluency_score\": {fluency_score},\n",
        "    \"pronunciation_score\": {pronunciation_score},\n",
        "    \"candidate_response\":{transcription},\n",
        "    \"fluency_feedback\": {feedback['fluency']},\n",
        "    \"grammar_feedback\": {feedback['grammar']},\n",
        "    \"pronunciation_feedback\": {feedback['pronunciation']},\n",
        "    \"num_pauses\": {num_pauses},\n",
        "    \"filler_words_count\": {len(filler_words)},\n",
        "    \"words_per_second\": {speaking_rate},\n",
        "    \"candidate_pronunciation\": {phonemes_speaker}\n",
        "}\n",
        "prompt = f\"\"\"\n",
        "You are an English language evaluation expert and a hiring manager. You will be provided with the assessment data and feedback from judges for a candidate on grammar, fluency, and pronunciation, along with the candidate's response. Your task is to evaluate the candidate's performance step-by-step, first presenting the judges' feedback as it is, and then explaining and elaborating on it using the provided scores, metrics, and response.\n",
        "\n",
        "Follow these steps:\n",
        "\n",
        "1. **Grammar Evaluation**:\n",
        "   - **Feedback**: Present the feedback for grammar exactly as provided by the judges.\n",
        "   - **Explanation and Elaboration**: Analyze the candidate's grammar based on the feedback, the score, and their response. Highlight specific strengths (e.g., accurate sentence structures) and weaknesses (e.g., grammatical errors like verb tense mismatches).\n",
        "\n",
        "2. **Fluency Evaluation**:\n",
        "   - **Feedback**: Present the feedback for fluency exactly as provided by the judges.\n",
        "   - **Explanation and Elaboration**: Assess the candidate's fluency using the score and following metrics:\n",
        "     - Number of filler words (e.g., \"um,\" \"uh,\" \"like\").\n",
        "     - Number of noticeable pauses.\n",
        "     - Words per second (WPS).\n",
        "   - Provide an analysis of strengths (e.g., smooth delivery) and areas needing improvement (e.g., reducing filler words, increasing pace).\n",
        "\n",
        "3. **Pronunciation Evaluation**:\n",
        "   - **Feedback**: Present the feedback for pronunciation exactly as provided by the judges.\n",
        "   - **Explanation and Elaboration**: Use the pronunciation score and the phones used by the candidate to evaluate clarity and articulation, highlighting specific strengths and weaknesses.\n",
        "\n",
        "Finally, consolidate your analysis into a detailed final report that includes:\n",
        "- The original judges' feedback for each section.\n",
        "- The elaboration and explanation for each section.\n",
        "- Specific, actionable recommendations for improvement.\n",
        "\n",
        "Feedback from Judges:\n",
        "- Grammar: {candidate_info['grammar_feedback']}\n",
        "- Fluency: {candidate_info['fluency_feedback']}\n",
        "- Pronunciation: {candidate_info['pronunciation_feedback']}\n",
        "Assessment Scores:\n",
        "- Grammar: {candidate_info['grammar_score']}/5\n",
        "- Fluency: {candidate_info['fluency_score']}/5\n",
        "- Pronunciation: {candidate_info['pronunciation_score']}/5\n",
        "\n",
        "Additional Metrics:\n",
        "- Fluency:\n",
        "  - Number of Filler Words: {candidate_info['filler_words_count']}\n",
        "  - Number of Pauses: {candidate_info['num_pauses']}\n",
        "  - Words per Second (WPS): {candidate_info['words_per_second']}\n",
        "- Pronunciation:\n",
        "  - Candidate's Pronunciation: {candidate_info['candidate_pronunciation']}\n",
        "\n",
        "Candidate's Response:\n",
        "{candidate_info['candidate_response']}\n",
        "\n",
        "Generate the final report with the structure specified.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "response = language_model.generate_content(prompt)\n",
        "print(\"Generated Report:\")\n",
        "print(response.text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "T8D37PTW5ju3",
        "outputId": "a8d79914-b724-4b7f-aa3e-4e64604e09ae"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Report:\n",
            "## Candidate Language Evaluation Report\n",
            "\n",
            "### Grammar Evaluation\n",
            "\n",
            "**Judges' Feedback**: \"Your grammar is adequate and generally understandable, but there is room for improvement in clarity and precision. Keep refining your skills.\"\n",
            "\n",
            "**Explanation and Elaboration**:\n",
            "The candidate's grammar score of 4.17 indicates that they generally use correct sentence structures and tenses. However, there is room for improvement in clarity and precision. Some specific areas for improvement could include:\n",
            "- Eliminating minor grammatical errors, such as verb tense mismatches (e.g., \"I was going yesterday\" instead of \"I went yesterday\").\n",
            "- Using more specific and precise language to enhance clarity and avoid ambiguity.\n",
            "- Proofreading written responses carefully to identify and correct any grammatical errors.\n",
            "\n",
            "### Fluency Evaluation\n",
            "\n",
            "**Judges' Feedback**: \"Your fluency is remarkable, with an effortless and natural flow. It is a pleasure to listen to!\"\n",
            "\n",
            "**Explanation and Elaboration**:\n",
            "The candidate's fluency score of 5.0 reflects their excellent delivery. Their speech is smooth and natural, without noticeable pauses or filler words. The candidate's words per second (WPS) rate of 1.2726188108967986 is within the optimal range for fluent speech.\n",
            "\n",
            "### Pronunciation Evaluation\n",
            "\n",
            "**Judges' Feedback**: \"Your pronunciation is adequate but could use some improvement. Working on specific sounds will enhance your speech.\"\n",
            "\n",
            "**Explanation and Elaboration**:\n",
            "The candidate's pronunciation score of 4.25 indicates that their pronunciation is generally clear, but there are some specific sounds that need attention. The provided phones {'ʌgaɪðhaʊɑɹjuduɪŋ'} suggest that the candidate may benefit from focusing on the following areas:\n",
            "- Articulating consonant sounds more clearly, particularly in word-initial and word-final positions (e.g., practicing words like \"cat,\" \"ball,\" and \"stop\").\n",
            "- Reducing vowel nasalization, especially in words like \"can,\" \"man,\" and \"sand.\"\n",
            "\n",
            "### Recommendations for Improvement\n",
            "\n",
            "Based on the assessment results and judges' feedback, the following recommendations are provided to assist the candidate in improving their English language skills:\n",
            "\n",
            "**Grammar**:\n",
            "- Regularly review grammar rules and practice using correct sentence structures.\n",
            "- Seek feedback from native speakers or language instructors to identify and correct grammatical errors.\n",
            "\n",
            "**Fluency**:\n",
            "- Engage in regular speaking practice, such as having conversations with native speakers or joining language exchange groups.\n",
            "- Practice delivering speeches or presentations to enhance pacing and reduce pauses.\n",
            "\n",
            "**Pronunciation**:\n",
            "- Focus on improving the pronunciation of specific sounds that need attention, using resources such as pronunciation dictionaries or online tutorials.\n",
            "- Practice speaking at a slightly slower pace to enhance clarity and articulation.\n"
          ]
        }
      ]
    }
  ]
}